{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  BM20A6100 Advanced Data Analysis and Machine Learning\n",
    "## Erik Kuitunen, 0537275"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 21:45:17.922184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731786317.956813  434797 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731786317.967010  434797 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-16 21:45:18.000239: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "import wordcloud\n",
    "import string\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and preprocess text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"Grimm Tales.txt\", 'rb')\n",
    "lines = []\n",
    "for line in file:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    \n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "    \n",
    "file.close()\n",
    "text = \" \".join(lines)\n",
    "\n",
    "# set of characters that occur in the text\n",
    "chars = set( [c for c in text] )\n",
    "\n",
    "# Total items in our vocabulary\n",
    "unique_chars = len( chars )\n",
    "\n",
    "# lookup tables to deal with indexes of characters rather than the characters themselves.\n",
    "char2index = dict( (c, i) for i, c in enumerate( chars ) )\n",
    "index2char = dict( (i, c) for i, c in enumerate( chars ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping and one-hot encoding of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 10\n",
    "step = 1\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range( 0, len(text) - sequence_length, step ):\n",
    "    input_chars.append(text[i:i + sequence_length])\n",
    "    label_chars.append(text[i + sequence_length])\n",
    "    \n",
    "X = np.zeros((len(input_chars), sequence_length, unique_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), unique_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 21:45:23.422313: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/eki/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False, \n",
    "                    input_shape=(sequence_length, unique_chars), \n",
    "                    unroll=True))\n",
    "model.add(Dense(unique_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #: 0\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7ms/step - loss: 2.1846\n",
      "\n",
      "Generating from seed: t, and her\n",
      "t, and her and said the sood the sood the sood the sood the Iteration #: 1\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 9ms/step - loss: 1.7435\n",
      "\n",
      "Generating from seed:  gift in r\n",
      " gift in round the wind was the princess and said the said tIteration #: 2\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 9ms/step - loss: 1.6021\n",
      "\n",
      "Generating from seed: n. gretel \n",
      "n. gretel on the fire and the should not be the should not bIteration #: 3\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9ms/step - loss: 1.5230\n",
      "\n",
      "Generating from seed: t, fell as\n",
      "t, fell as the word was a little was stood a little was stooIteration #: 4\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 9ms/step - loss: 1.4788\n",
      "\n",
      "Generating from seed:  i could b\n",
      " i could be a great down and said the stars and said the staIteration #: 5\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 10ms/step - loss: 1.4399\n",
      "\n",
      "Generating from seed:  as she sa\n",
      " as she said the man that was a sad and said, i will go and Iteration #: 6\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9ms/step - loss: 1.4154\n",
      "\n",
      "Generating from seed: e long ste\n",
      "e long step and said: i will said the forest the forest the Iteration #: 7\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 10ms/step - loss: 1.3964\n",
      "\n",
      "Generating from seed: n, said th\n",
      "n, said the cook where the seat the seat the seat the seat tIteration #: 8\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 10ms/step - loss: 1.3836\n",
      "\n",
      "Generating from seed:  is alread\n",
      " is already and drank the wall from the way, and the third tIteration #: 9\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - loss: 1.3688\n",
      "\n",
      "Generating from seed:  which eve\n",
      " which evening the flower the starse the should be down and Iteration #: 10\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 10ms/step - loss: 1.3554\n",
      "\n",
      "Generating from seed: could be s\n",
      "could be so do you will go home and the stoed the spat the sIteration #: 11\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 13ms/step - loss: 1.3464\n",
      "\n",
      "Generating from seed: otherwise \n",
      "otherwise the wind with her father was strenged to see the gIteration #: 12\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9ms/step - loss: 1.3428\n",
      "\n",
      "Generating from seed:  down whol\n",
      " down whole day in her by the beautiful place a great the prIteration #: 13\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 1.3380\n",
      "\n",
      "Generating from seed: alk, that \n",
      "alk, that is a little to her good the stone of the stars wasIteration #: 14\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.3250\n",
      "\n",
      "Generating from seed: rrow, and \n",
      "rrow, and said: the golden bride was the golden bride was thIteration #: 15\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.3217\n",
      "\n",
      "Generating from seed: kings daug\n",
      "kings daughter to the time the world and said: if the world Iteration #: 16\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.3203\n",
      "\n",
      "Generating from seed:  it would \n",
      " it would not know what will be a little toor the will not sIteration #: 17\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.3145\n",
      "\n",
      "Generating from seed: that would\n",
      "that would not seen the soldier stood the soldier stood the Iteration #: 18\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.3102\n",
      "\n",
      "Generating from seed: aming with\n",
      "aming with his done and said the spinned him the spindle, anIteration #: 19\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.3047\n",
      "\n",
      "Generating from seed:  thou, que\n",
      " thou, queen her father was a little way of a little way of Iteration #: 20\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.3045\n",
      "\n",
      "Generating from seed: place; so \n",
      "place; so she said, i will go with him and said: i will go wIteration #: 21\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.2992\n",
      "\n",
      "Generating from seed: ever, and \n",
      "ever, and the stream and the stream and the stream and the sIteration #: 22\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.2974\n",
      "\n",
      "Generating from seed: f stone. t\n",
      "f stone. the wood said the fire and said: i will not said toIteration #: 23\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.2903\n",
      "\n",
      "Generating from seed:  the bird \n",
      " the bird and said: i will the carried the carried the carriIteration #: 24\n",
      "\u001b[1m4011/4011\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 1.2898\n",
      "\n",
      "Generating from seed:  chest; ta\n",
      " chest; take him a forest and said: i will go to the stars a"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    \n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    \n",
    "    print(\"\\nGenerating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    \n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros( (1, sequence_length, unique_chars) )\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\\n\")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "# print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
